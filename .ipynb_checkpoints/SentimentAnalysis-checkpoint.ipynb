{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa624936-bf55-4673-88aa-3db59b829335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.15\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ac8906e-f073-45bc-9d4a-59309cd2cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e36e14a4-4fa5-4ebf-89b8-44391186774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e2e26de-000e-48f4-b25e-c0740a45ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3c67745-accf-48b1-9994-8d6cc1172cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: iso8859_10\n",
      "   ItemID  Sentiment                                      SentimentText\n",
      "0       1          0                       is so sad for my APL frie...\n",
      "1       2          0                     I missed the New Moon trail...\n",
      "2       3          1                            omg its already 7:30 :O\n",
      "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
      "4       5          0           i think mi bf is cheating on me!!!   ...\n"
     ]
    }
   ],
   "source": [
    "from charset_normalizer import from_path\n",
    "\n",
    "file_path = \"Dataset/SentimentAnalysisDataset1.csv\"\n",
    "result = from_path(file_path).best()\n",
    "print(\"Detected encoding:\", result.encoding)\n",
    "\n",
    "df1 = pd.read_csv(file_path, encoding=result.encoding)\n",
    "\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dbb627f1-7675-4485-94e6-c7b5f1ce990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ItemID  Sentiment                                      SentimentText\n",
      "0       1          0                       is so sad for my APL frie...\n",
      "1       2          0                     I missed the New Moon trail...\n",
      "2       3          1                            omg its already 7:30 :O\n",
      "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
      "4       5          0           i think mi bf is cheating on me!!!   ...\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Dataset/SentimentAnalysisDataset2.csv\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "with open(\"Dataset/SentimentAnalysisDataset2_UTF8.csv\", 'wb') as f:\n",
    "    f.write(content.decode('cp1252', errors='replace').encode('utf-8'))\n",
    "\n",
    "df2 = pd.read_csv(\"Dataset/SentimentAnalysisDataset2_UTF8.csv\")\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f622e7f2-a87d-414f-b8f8-564b6f1ba8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ItemID  Sentiment                                      SentimentText\n",
      "0             1          0                       is so sad for my APL frie...\n",
      "1             2          0                     I missed the New Moon trail...\n",
      "2             3          1                            omg its already 7:30 :O\n",
      "3             4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
      "4             5          0           i think mi bf is cheating on me!!!   ...\n",
      "...         ...        ...                                                ...\n",
      "1148559   99996          0  @Cupcake  seems like a repeating problem   hop...\n",
      "1148560   99997          1  @cupcake__ arrrr we both replied to each other...\n",
      "1148561   99998          0                     @CuPcAkE_2120 ya i thought so \n",
      "1148562   99999          1  @Cupcake_Dollie Yes. Yes. I'm glad you had mor...\n",
      "1148563  100000          1                    @cupcake_kayla haha yes you do \n",
      "\n",
      "[1148564 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "346bfee4-4420-46c6-865f-cf7ab307a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148564, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f9584c2-50ad-4359-b53f-540b25a28848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'Sentiment', 'SentimentText'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b180ec21-2412-453e-b66a-c2bc7c73394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e7438fd-2390-46bd-b225-9fa339784bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"SentimentText\",\"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6352fb64-6db4-4350-aa55-212bdd387b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment\n",
       "0                       is so sad for my APL frie...          0\n",
       "1                     I missed the New Moon trail...          0\n",
       "2                            omg its already 7:30 :O          1\n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...          0\n",
       "4           i think mi bf is cheating on me!!!   ...          0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a61cf7a-e0e1-49d5-b6f6-59c39bdbc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"Dataset/SentimentAnalysisDataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16e19a36-1326-4118-983e-cc37567f4b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1381b38-41bb-4020-88ad-f7fb344fd6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    610927\n",
       "0    537637\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d9d71b9-6158-4082-bdf9-fbeaaf182c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_df['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34a0d8-b279-4884-b869-f3fc532c57bb",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "Here’s a breakdown of the two lines of code and what they do:\n",
    "\n",
    "#### **Code:**\n",
    "```python\n",
    "train_df['sentence_no_punctuation'] = train_df['SentimentText'].str.replace('[^\\w\\s]','')\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "- This creates a new column in the DataFrame called `sentence_no_punctuation`.\n",
    "- It removes all punctuation from the text in the `SentimentText` column.\n",
    "  - **`str.replace()`**: Applies a string replacement to all rows in the column.\n",
    "  - **`[^\\w\\s]`**: This is a **regular expression (regex)** pattern that matches any character **except** word characters (`\\w`) or whitespace (`\\s`).\n",
    "  - **`''`**: Replaces the matched characters (punctuation) with an empty string.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Code:**\n",
    "```python\n",
    "train_df['sentence_no_punctuation'] = train_df[\"sentence_no_punctuation\"].fillna(\"fillna\")\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "- This replaces any missing (`NaN`) values in the `sentence_no_punctuation` column with the string `\"fillna\"`.\n",
    "- **`fillna(\"fillna\")`**: \n",
    "  - Ensures that the column has no `NaN` values, replacing them with the string `\"fillna\"`.\n",
    "  - Useful for handling missing data when working with text processing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose**\n",
    "1. **Remove punctuation**: To simplify text data for tasks like sentiment analysis or tokenization.\n",
    "2. **Handle missing values**: Ensures the new column is consistent and doesn’t contain any `NaN` values, which might cause errors during analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Result**\n",
    "After executing this code:\n",
    "- The column `sentence_no_punctuation` will contain the same text as `SentimentText`, but with all punctuation removed.\n",
    "- Any `NaN` values in this new column will be replaced by `\"fillna\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02cc592b-9052-48d5-afe7-cfdedf58770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110/3609360619.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['sentence_no_punctuation'] = train_df['SentimentText'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "train_df['sentence_no_punctuation'] = train_df['SentimentText'].str.replace('[^\\w\\s]','')\n",
    "train_df['sentence_no_punctuation'] = train_df[\"sentence_no_punctuation\"].fillna(\"fillna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32439ed4-c19c-49ce-90dd-4c25dd5cca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 656158\n",
    "maxlen = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfa9f4-87d9-4cf8-9c34-43aff7978354",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### **Code:**\n",
    "```python\n",
    "tok = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "- Creates an instance of the `Tokenizer` class from TensorFlow's `keras.preprocessing.text` module.\n",
    "- This tokenizer is used for preparing text data for machine learning models, specifically for converting text into numerical sequences.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`num_words=max_features`**: \n",
    "  - Specifies the maximum number of unique words (vocabulary size) to keep when tokenizing the text.\n",
    "  - Only the `max_features` most frequent words in the text corpus will be retained.\n",
    "  - Any words beyond this limit will be ignored during tokenization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features of the `Tokenizer`**\n",
    "1. **Builds a word index**: Maps each unique word in the text corpus to a unique integer index.\n",
    "2. **Filters out rare words**: Keeps only the most frequent `max_features` words.\n",
    "3. **Tokenizes text**: Converts sequences of words into sequences of integers based on the word index.\n",
    "4. **Handles out-of-vocabulary words**: Words not in the top `max_features` are replaced with a special token (if configured).\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose**\n",
    "This is typically the first step in processing text data for machine learning tasks like sentiment analysis, text classification, or language modeling. By tokenizing text into numerical sequences, the data becomes compatible with numerical models, such as neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a02e011-4cdc-43e0-8d0d-af28b0f3c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tf.keras.preprocessing.text.Tokenizer(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ac3657d-a748-4d5d-8ea1-256aa2390123",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(list(train_df['sentence_no_punctuation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355e7b5-a23b-4f1d-a76d-706e03121529",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### **Code:**\n",
    "```python\n",
    "print(len(tok.word_index))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Explanation**\n",
    "\n",
    "1. **`len(tok.word_index)`**\n",
    "   - The `tok.word_index` is a dictionary created by the `Tokenizer` that maps each unique word in the text corpus to a unique integer index.\n",
    "   - `len(tok.word_index)` returns the total number of unique words (or tokens) identified in the text corpus.\n",
    "\n",
    "---\n",
    "\n",
    "2. **`vocab_size = len(tok.word_index) + 1`**\n",
    "   - The vocabulary size (`vocab_size`) is defined as the total number of unique words **plus one**.\n",
    "   - Why **`+1`**? \n",
    "     - The additional \"1\" accounts for the **reserved index 0**, which is often used in deep learning models to represent padding tokens (for aligning sequences of different lengths).\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose**\n",
    "- Printing `len(tok.word_index)` helps understand the total vocabulary size identified by the tokenizer.\n",
    "- Adding 1 ensures the vocabulary size includes a reserved index for padding, which is commonly required in neural networks for sequence processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc6f95e5-70c6-4769-98dc-ab33f8599544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656158\n"
     ]
    }
   ],
   "source": [
    "print(len(tok.word_index))\n",
    "vocab_size = len(tok.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f82d0a-1117-41a7-9c72-165c07581079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
